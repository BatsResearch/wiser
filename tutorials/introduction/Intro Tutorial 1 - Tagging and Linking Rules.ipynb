{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# An Introduction to WISER, Part 1: Tagging and Linking Rules\n",
    "\n",
    "Welcome to WISER (*Weak and Indirect Supervision for Entity Recognition*), a system for training sequence-to-sequence models, particularly neural networks for named entity recognition (NER) and related tasks. WISER uses *weak supervision* in the form of rules to train these models, as opposed to hand-labeled training data.\n",
    "\n",
    "In this first part of the tutorial, we will be writing tagging and linking rules to identify actor and acress names, awards, and movies from a text corpus of actor descriptions extracted from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "WISER is an add-on to [Allen NLP](http://allennlp.org), a great framework for natural language processing. That means we can use their tools for working with data.\n",
    "\n",
    "Let's start by loading the MovieAwards dataset, a new NEW dataset we created just for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from wiser.data.dataset_readers import MediaDatasetReader\n",
    "\n",
    "dataset_reader = MediaDatasetReader()\n",
    "train_data = dataset_reader.read('data/wikipedia/unlabeled_train.csv')\n",
    "dev_data = dataset_reader.read('data/wikipedia/labeled_dev.csv')\n",
    "test_data = dataset_reader.read('data/wikipedia/labeled_test.csv')\n",
    "\n",
    "\"\"\" We must merge data partitions to simultaneously apply rules to them \"\"\" \n",
    "data = train_data + dev_data + test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to use WISER with other data sets is to implement a new subclass of AllenNLP's [DatasetReader](https://allenai.github.io/allennlp-docs/api/allennlp.data.dataset_readers.dataset_reader.html#allennlp.data.dataset_readers.dataset_reader.DatasetReader). We have some additional examples in the package `wiser.data.dataset_readers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data\n",
    "Once the data is loaded, we use a WISER class called `Viewer` to inspect the sentences and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        // Main rendering function\n",
       "        render: function() {\n",
       "            // Insert the html\n",
       "            this.$el.append(this.model.get('html'));\n",
       "            this.nPages = this.model.get('n_instances');\n",
       "            this.$el.append(this.nPages);\n",
       "            // Set the instance id\n",
       "            this.id  = 0;\n",
       "            // Set the label source\n",
       "            this.source = 0;\n",
       "\n",
       "            // Enable buttons for changing page\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "\n",
       "            // Enable select menu for changing label source\n",
       "            this.$el.find(\"#source\").change(function() {\n",
       "                that.switchSource();\n",
       "            })\n",
       "        },\n",
       "\n",
       "        switchPage: function(inc) {\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.id + inc < 0) {\n",
       "                this.id = 0;\n",
       "            } else if (this.id + inc >= this.nPages - 1) {\n",
       "                this.id = this.nPages - 1;\n",
       "            } else {\n",
       "                this.id += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.id+\"-\"+this.source).show();\n",
       "\n",
       "            // Show page id\n",
       "            this.$el.find(\"#page\").html(this.id);\n",
       "        },\n",
       "\n",
       "        switchSource: function() {\n",
       "            this.source = this.$el.find(\"#source\").val();\n",
       "            this.switchPage(0);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109c6496dd084f1b9056b3b6ac0c2164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(html='<head>\\n<style>\\nspan.active {\\n    background-color: skyblue;\\n    box-shadow: 1px 1px 1px grey;â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wiser.viewer import Viewer\n",
    "\n",
    "Viewer(dev_data, height=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the left and right buttons to flip through the items in `dev_data`, each of which is an AllenNLP [`Instance`](https://allenai.github.io/allennlp-docs/api/allennlp.data.instance.html#allennlp.data.instance.Instance). The highlighted spans are the entities, and you can hover over each one with your cursor to see whether it is an award (AWD), or movie (MOV).\n",
    "\n",
    "The drop-down menu selects which source of labels is displayed. Currently only the gold labels from the benchmark are available, but we will add more soon.\n",
    "\n",
    "Advance to the instance at index 4 to see an example with multiple entities of different classes. You can access the underlying tokens and tags too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that WISER uses the [IOB1 tagging scheme](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), meaning that entities are represented as consecutive tags beginning with `I`. Many data sets use subsequent characters for different classes, for example `-ACT` and `-MOV` here for actor/actress and movie, respectively. The `O` tag means that the token is not part of an entity. There is also a special set of tags beginning with `B` (like those beginning with `I`) that are used to start a new entity that immediately follows another of the same class without an `O` tag in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Rules\n",
    "Tagging rules are functions that map text instances to sequences of labels. We can define our own tagging rules by writing small functions that look at sequences of instance tokens, and vote on their correponding tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Tagging Rules\n",
    "From inspecting the data, we know tokens proper nouns followed by a year/years between parentheses are likely tagged as movies. Therefore, we can write our first tagging rule to reflect this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import TaggingRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieYear(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        for i in range(len(tokens)-2):\n",
    "            \n",
    "            # Proper nouns followed by a numerical year between parentheses\n",
    "            if tokens[i].istitle() and tokens[i+1] == '(' and tokens[i+2].isdigit():\n",
    "                labels[i] = 'I-MOV'\n",
    "               \n",
    "        return labels\n",
    "\n",
    "lf = MovieYear()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fp = {'network', 'netflix', 'hulu', 'bbc', 'fox', 'disney', 'hbo', 'cbs',\n",
    "             'channel', 'american', 'british', 'television', 'showtime', 'productions'}\n",
    "\n",
    "class CommonFP(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in common_fp:\n",
    "                labels[i] = 'O'\n",
    "               \n",
    "        return labels\n",
    "\n",
    "lf = CommonFP()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also look at previous tagging rules to make more complex functions. However, be mindful of the order in which you run the tagging functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_keywords = {'trilogy', 'miniseries', 'saga', 'series', 'miniseries', \n",
    "            'show', 'sitcom', 'drama', 'musical', 'franchise'}\n",
    "# Suggested: film, prequel, sequel, 'thriller', 'opera'\n",
    "\n",
    "class MovieKeywords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        false_positives = [t for t in instance['WISER_LABELS']['CommonFP']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in movie_keywords:\n",
    "                \n",
    "                \"\"\"\n",
    "                    We will only tag a word as a movie if \n",
    "                    the false positive rule asbtained from voting it\n",
    "                    (e.g., we want to avoid false positives such as \n",
    "                    \"Hulu\" in sentences like \"The Hulu miniseries\")\n",
    "\n",
    "                    We also want to avoid some award names \n",
    "                    like \" ... Musical Drama\", etc.\n",
    "                \"\"\" \n",
    "                \n",
    "                # Keywords followed by movies (e.g., Kung-Fu Panda franchise)\n",
    "                if i < len(tokens) and tokens[i+1].istitle() and false_positives[i+1] == 'ABS':\n",
    "                    if tokens[i+1].lower() not in movie_keywords:\n",
    "                        labels[i+1] = 'I-MOV'\n",
    "                       \n",
    "                # Movies followed by keywords (e.g., The TV series The Mandalorian)\n",
    "                elif i > 0 and tokens[i-1].istitle() and false_positives[i-1] == 'ABS':\n",
    "                    if tokens[i-1].lower() not in movie_keywords:\n",
    "                        labels[i-1] = 'I-MOV'\n",
    "        return labels\n",
    "\n",
    "lf = MovieKeywords()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use existing tagging functions and helpers available at `wiser.lf`. DictionaryMatcher is a tagging function helper that allows us to quickly create a new rule that votes on tokens encountered in in a particular set using a predefined tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import DictionaryMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good trick to developing efficient sequence taggers is to also generate some negative supervision in the form of *O* tags. We can therefore write a  function to tag punctuations signs as *O*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add your own characters to the set!\n",
    "non_entity_punctuation_chars = {'.', ';', '(', ')'}\n",
    "\n",
    "lf = DictionaryMatcher(\"Non-Entity-Punctuation\", terms=non_entity_punctuation_chars, i_label=\"O\")\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Tagging Rules\n",
    "We can evalualte labeling functions on the development set in either of two ways. First, we can inspect individual labeling functions using the ``score_labeling_functions`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Token Acc.</th>\n",
       "      <th>Token Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CommonFP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieKeywords</th>\n",
       "      <td>45</td>\n",
       "      <td>148</td>\n",
       "      <td>1567</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieYear</th>\n",
       "      <td>163</td>\n",
       "      <td>662</td>\n",
       "      <td>1449</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Entity-Punctuation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         TP   FP    FN  Token Acc.  Token Votes\n",
       "CommonFP                  0    0  1612      0.9048          315\n",
       "MovieKeywords            45  148  1567      0.9124          194\n",
       "MovieYear               163  662  1449      0.9661          825\n",
       "Non-Entity-Punctuation    0    0  1612      0.9976         2970"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiser.eval import score_tagging_rules\n",
    "\n",
    "score_tagging_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect at the precision, recall, and F1 scores of the combined labeling rules with ``score_labels_majority_vote``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Majority Vote</th>\n",
       "      <td>217</td>\n",
       "      <td>775</td>\n",
       "      <td>1395</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TP   FP    FN       P       R      F1\n",
       "Majority Vote  217  775  1395  0.2188  0.1346  0.1667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiser.eval import score_labels_majority_vote\n",
    "\n",
    "score_labels_majority_vote(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Rules\n",
    "Linking rules are functions that vote on whether two or more adjacent tokens belong should belong to the same entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Linking Rules\n",
    "Tagging rules do not always correctly vote on all the tokens in multi-span entities. For instance, a rule may only tag the *Barack* as a name in the string span *Barack Obama*. Therefore, we can write linking rules to indicate that *Barack* and *Obama* should share the same tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import LinkingRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveCapitals(LinkingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i-1].istitle() and tokens[i].istitle():\n",
    "                links[i] = 1\n",
    "        return links\n",
    "\n",
    "lf = ConsecutiveCapitals()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkers = {':', ';', '-'}\n",
    "\n",
    "class SentenceLinkers(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in linkers:\n",
    "                links[i] = 1\n",
    "                links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lf = SentenceLinkers()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_suffixes = {'\\'s', '\\'nt', '\\'ve'}\n",
    "\n",
    "class Contractions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i] in contraction_suffixes:\n",
    "                links[i] = 1\n",
    "        return links\n",
    "\n",
    "lf = Contractions()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_prepositions = {'a', 'the', 'at', 'with', 'of'}\n",
    "# Suggestions: in, by, for\n",
    "class CommonPrepositions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in common_prepositions:\n",
    "                if tokens[i-1].istitle() and tokens[i+1].istitle():\n",
    "                    links[i] = 1\n",
    "                    links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lf = CommonPrepositions()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Linking Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to tagging rules, we can evaluate the accuracy of our linking rules using the ``score_linking_functions`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Links</th>\n",
       "      <th>Non-Entity Links</th>\n",
       "      <th>Incorrect Links</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CommonPrepositions</th>\n",
       "      <td>206</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ConsecutiveCapitals</th>\n",
       "      <td>1738</td>\n",
       "      <td>816</td>\n",
       "      <td>17</td>\n",
       "      <td>0.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contractions</th>\n",
       "      <td>38</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceLinkers</th>\n",
       "      <td>182</td>\n",
       "      <td>404</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Entity Links  Non-Entity Links  Incorrect Links  Accuracy\n",
       "CommonPrepositions            206                75                1    0.9965\n",
       "ConsecutiveCapitals          1738               816               17    0.9934\n",
       "Contractions                   38               111                0    1.0000\n",
       "SentenceLinkers               182               404               12    0.9799"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiser.eval import score_linking_rules\n",
    "\n",
    "score_linking_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Progress\n",
    "We can use pickle to store the data with the tagging and linking rules applied to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('output/tmp/train_data.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open('output/tmp/dev_data.p', 'wb') as f:\n",
    "    pickle.dump(dev_data, f)\n",
    "\n",
    "with open('output/tmp/test_data.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed part 1! Now you can move on to part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
