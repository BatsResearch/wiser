{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# An Introduction to WISER, Part 1: Tagging and Linking Rules\n",
    "\n",
    "Welcome to WISER (*Weak and Indirect Supervision for Entity Recognition*), a system for training sequence-to-sequence models, particularly neural networks for named entity recognition (NER) and related tasks. WISER uses *weak supervision* in the form of rules to train these models, as opposed to hand-labeled training data.\n",
    "\n",
    "In this first part of the tutorial, we will be writing tagging and linking rules to identify award names, alongside movies, T.V. shows and plays from a text corpus extracted from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "WISER is an add-on to [AllenNLP](http://allennlp.org), a great framework for natural language processing. That means we can use their tools for working with data.\n",
    "\n",
    "Let's start by loading the Media dataset, a new dataset we created just for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from wiser.data.dataset_readers import MediaDatasetReader\n",
    "\n",
    "dataset_reader = MediaDatasetReader()\n",
    "train_data = dataset_reader.read('data/wikipedia/unlabeled_train.csv') # Reads only data for 100 actors\n",
    "dev_data = dataset_reader.read('data/wikipedia/labeled_dev.csv')\n",
    "test_data = dataset_reader.read('data/wikipedia/labeled_test.csv')\n",
    "\n",
    "# We must merge the data to to simultaneously apply rules to it\n",
    "data = train_data + dev_data + test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to use WISER with other data sets is to implement a new subclass of AllenNLP's [DatasetReader](https://allenai.github.io/allennlp-docs/api/allennlp.data.dataset_readers.dataset_reader.html#allennlp.data.dataset_readers.dataset_reader.DatasetReader). We have some additional examples in the package `wiser.data.dataset_readers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data\n",
    "Once the data is loaded, we use a WISER class called `Viewer` to inspect the sentences and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Viewer(html='<head>\\n<style>\\nspan.active {\\n    background-color: skyblue;\\n    box-shadow: 1px 1px 1px grey;â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wiser.viewer import Viewer\n",
    "Viewer(dev_data, height=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the left and right buttons to flip through the items in `dev_data`, each of which is an AllenNLP [`Instance`](https://allenai.github.io/allennlp-docs/api/allennlp.data.instance.html#allennlp.data.instance.Instance). The highlighted spans are the entities, and you can hover over each one with your cursor to see whether it is an award (**AWD**), or one of a movie, T.V. show, or play (**MOV**).\n",
    "\n",
    "The drop-down menu selects which source of labels is displayed. Currently only the gold labels from the benchmark are available, but we will add more soon.\n",
    "\n",
    "Advance to the instance at index 4 to see an example with multiple entities of different classes. You can access the underlying tokens and tags too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that WISER uses the [IOB1 tagging scheme](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), meaning that entities are represented as consecutive tags beginning with **I**. Many data sets use subsequent characters for different classes, for example **-AWD** and **-MOV** here for awards and movies/T.V. shows/plays, respectively. The **O**, or other tag, means that the token is not part of an entity. There is also a special set of tags beginning with **B** (like those beginning with **I**) that are used to start a new entity that immediately follows another of the same class without an **O** tag in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Rules\n",
    "Tagging rules are functions that map unlabeled text instances to sequences of labels. We can define our own tagging rules by writing small functions that look at sequences of instance tokens, and vote on their correponding tags. Let's first import the ``TaggingRule`` class from ``wiser.lf``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import TaggingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Simple Tagging Rules\n",
    "From inspecting the data, we know tokens proper nouns followed by a year between parentheses are likely tagged as movies. For instance, the token ``Friends`` in the span ``Friends (1994 - 2004)`` should be tagged **I-MOV**. Therefore, we can write our first tagging rule to reflect this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieYear(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        # Creates a list of token strings to inspect\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        \n",
    "        # Initializes a list of abstained label votes \n",
    "        # (All abstained votes should have the ABS tag)\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        # Iterates over the list of tokens\n",
    "        for i in range(len(tokens)-2):    \n",
    "            # Tags as movies all proper nouns followed by a number between parentheses\n",
    "            if tokens[i].istitle() and tokens[i+1] == '(' and tokens[i+2].isdigit():\n",
    "                labels[i] = 'I-MOV'\n",
    "               \n",
    "        # Returns the modified label vote list\n",
    "        return labels\n",
    "\n",
    "# Applies the tagging rule to all dataset entries \n",
    "lf = MovieYear()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write a tagging rule to identify award categories like ``for Oustanding Lead Actress`` in award spans such as ``BAFTA Award for Oustanding Lead Actress``. Categories are generally preceded by capitalized letters, and follow with the strings ``for Oustanding`` or ``for Best`` (skip to instance at index 27 to see an example of this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AwardCategory(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        for i in range(len(tokens)-2):\n",
    "            if tokens[i].istitle() and tokens[i+1] == 'for' and tokens[i+2] in {'Best', 'Oustanding'}:\n",
    "                # We tag the \"for\" and \"Best\"/\"Outstanding\" tokens as award names\n",
    "                labels[i+1] = 'I-AWD'\n",
    "                labels[i+2] = 'I-AWD'\n",
    "               \n",
    "        return labels\n",
    "\n",
    "lf = AwardCategory()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Function Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use existing tagging functions and helpers available at `wiser.lf`. The ``DictionaryMatcher`` is a tagging function helper that allows us to quickly create a new rule that votes on any element found in a list or set of characters or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import DictionaryMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tag some award keywords! Any token spelling ``Award`` , ``Awards``, ``Prize`` or ``Cup`` should be tagged as an award. Be mindful of capitalization, since awards are generally proper nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_keywords = [['Award'], ['Awards'], ['Prize'], ['Cup']]\n",
    "                  \n",
    "lf = DictionaryMatcher(\"AwardKeywords\", terms=award_keywords, i_label=\"I-AWD\", uncased=False)\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good trick to developing efficient sequence taggers is to also generate some negative supervision in the form of **O** tags. To do so, we can write a function to tag punctuations signs as **O** tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_entity_punctuation_chars = {'.', ';', '(', ')'}\n",
    "\n",
    "lf = DictionaryMatcher(\"Non-EntityPunctuation\", terms=non_entity_punctuation_chars, i_label=\"O\")\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend going over the data and identifying a few false positive tokens. That is, tokens that are similar to entities but are not (e.g., capitalized tokens such as studio names, and recurrent proper nouns near movie titles). We will also write a `DictionaryMatcher` identify some common false positives and tag them as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_false_positives = [['network'], ['netflix'], ['hulu'], ['bbc'], ['fox'], \n",
    "                          ['disney'], ['hbo'], ['CBS'], ['channel'], ['american'], \n",
    "                         ['showtime'], ['productions'], ['TV']]\n",
    "\n",
    "lf = DictionaryMatcher(\"CommonFalsePositives\", terms=common_false_positives, i_label=\"O\", uncased=True)\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Previous Tagging Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also develop more complex tagging rules by looking at previous tagging rule votes using the ``WISER_LABELS`` field. However, be mindful of the order in which you run the tagging functions.\n",
    "\n",
    "In the following example, we will write a tagging rule to identify typical keywords preceding or **MOV** tags (e.g., ``The TV series The Mandalorian``) or succeeding them (e.g., ``Kung-Fu Panda franchise``). However, we also want to avoid tagging some common false positive tags (e.g., ``TV``) as movies, which is why we will reference the output votes of the ``CommonFalsePositives`` rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_keywords = {'trilogy', 'saga', 'series', 'miniseries', \n",
    "                'show', 'opera', 'drama', 'musical', 'sequel',\n",
    "                'prequel', 'franchise', 'thriller', 'sitcom'}\n",
    "\n",
    "class MovieKeywords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        # List of tag votes of CommonFalsePositives rule\n",
    "        false_positives = [t for t in instance['WISER_LABELS']['CommonFalsePositives']]\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in movie_keywords:\n",
    "                \n",
    "                \"\"\"\n",
    "                    We will only tag a word as a movie if \n",
    "                    the CommonFalsePositives asbtained from voting it\n",
    "                    (e.g., we want to avoid false positives such as \n",
    "                    \"Hulu\" in spans like \"the Hulu miniseries\")\n",
    "\n",
    "                    We also want to avoid award names \n",
    "                    like \"... Musical Drama\", etc.\n",
    "                \"\"\" \n",
    "                \n",
    "                # Keywords followed by movies (e.g., Kung-Fu Panda franchise)\n",
    "                if i < len(tokens) and tokens[i+1].istitle() and false_positives[i+1] == 'ABS':\n",
    "                    if tokens[i+1].lower() not in movie_keywords:\n",
    "                        labels[i+1] = 'I-MOV'\n",
    "                       \n",
    "                # Movies followed by keywords \n",
    "                elif i > 0 and tokens[i-1].istitle() and false_positives[i-1] == 'ABS':\n",
    "                    if tokens[i-1].lower() not in movie_keywords:\n",
    "                        labels[i-1] = 'I-MOV'\n",
    "        return labels\n",
    "\n",
    "lf = MovieKeywords()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Existing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also recommend having one or two tagging rules that adds a lot of negative supervision in the form of O tags with high recall. These types of rules are generally weighted in the discriminative model to strike a balance between positive entity and non-entity votes.\n",
    "\n",
    "For this, we will use nltk's [part-of-speech tagger]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tagger = nlp.create_pipe(\"tagger\")\n",
    "\n",
    "\n",
    "class NonEntityWords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        \n",
    "        parts_of_speech = [token[0].pos_ for token in nlp.pipe(tokens)]        \n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        for i, (token, pos) in enumerate(zip(tokens, parts_of_speech)):\n",
    "            if pos in {'NOUN', 'VERB', 'ADJ', 'SPACE', 'NUM'} and not token.istitle():\n",
    "                labels[i] = 'O'\n",
    "        return labels\n",
    "\n",
    "lf = NonEntityWords()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Tagging Rules\n",
    "We can inspect the performance of individual labeling functions on the development set using the ``score_labeling_functions`` method. \n",
    "\n",
    "* True positives (TP) represent the number of items correctly labeled items as belonging to a positive class (e.g. **I-MOV**).\n",
    "\n",
    "* False positives (FP) are the number of items incorrectly labeled as belonging to a positive class.\n",
    "\n",
    "* False Negatives (FN) are the items which were not labeled as belonging to the positive class but should have been.\n",
    "\n",
    "* Token Accuracy (Token Acc.) represents the fraction of issued votes that correctly identified a positive class.\n",
    "\n",
    "* Token Votes is the total number of times the tagging rules issued a vote belongint to a positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.eval import score_tagging_rules\n",
    "score_tagging_rules(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for instance in dev_data:\n",
    "    for tok in instance['tokens']:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb is to write tagging rules whose accuracy is above 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Rules\n",
    "Linking rules are simple functions that vote on whether two or more adjacent tokens belong should belong to the same entity. To get started with linking rules, you can import the ``LinkingRule`` class from ``wiser.lf``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import LinkingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Linking Rules\n",
    "Tagging rules do not always correctly vote on *all* the tokens in multi-span entities. For instance, the **MovieYear** tagging rule only tag the last token in a movie span. For instance, it would only tag ``Gatsby`` as **I-MOV** in ``The Great Gatsby (2013)``.\n",
    "\n",
    "Our job is to ensure that the entire class spans are tagged correctly. For instance, we could write a linking rule to indicate that consecutively capitalized words should share the same tag. Therefore, voting that ``The`` and ``Great`` share the same tag as ``Gatsby`` would tag the entire movie name as **I-MOV**, rather than the last token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveCapitals(LinkingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i-1].istitle() and tokens[i].istitle():\n",
    "                links[i] = 1 # token at index \"i\" shares tag with token at index \"i-1\"\n",
    "        return links\n",
    "\n",
    "lf = ConsecutiveCapitals()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data we have also observed several movie and award names that have hyphens, semicolons or colons (e.g. ``Avengers: Endgame``). We can write a linking rule to indicate that these linking punctuation characters, along with their preceding and succeeding token, should all be a part of the same entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkers = {':', ';', '-'}\n",
    "\n",
    "class PunctuationLinkers(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in linkers:\n",
    "                \n",
    "                # The linking punctuation character and it's succeeding character\n",
    "                # share the same tag as the preceding one at index \"i-1\"\n",
    "                links[i] = 1\n",
    "                links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lf = PunctuationLinkers()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can write a rule to indicate that contractions share the same tag with the token preceding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_suffixes = {'\\'s', '\\'nt', '\\'ve', '\\'', '\\'d'}\n",
    "\n",
    "class Contractions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i] in contraction_suffixes:\n",
    "                links[i] = 1\n",
    "        return links\n",
    "\n",
    "lf = Contractions()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also link noun phrases that using a list of common prepositions in award and movie names. These prepositions are part of award and movie names, and are usually lowercase and adjacent to or other prepositions or capitalized words. For example, ``Golden Globe for Best Actor`` or ``Guardians of the Galaxy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_prepositions = {'a', 'the', 'at', 'with', 'of', 'by', '&', 'with'}\n",
    "\n",
    "class CommonPrepositions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in common_prepositions:\n",
    "                if tokens[i-1].istitle() or tokens[i-1] in common_prepositions:\n",
    "                    if tokens[i+1].istitle() or tokens[i+1] in common_prepositions:\n",
    "                        links[i] = 1\n",
    "                        links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lf = CommonPrepositions()\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Rule Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to tagging rules, we have linking rule helpers available at ``wiser.lf``. For the next linking rule, we will use the ``ElmoLinkingRule``, a rule that vectorizes tokens using [Elmo](https://allennlp.org/elmo) and links those with a cosine similaritiy larger than a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import ElmoLinkingRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We link tokens whose cosine similarity is larger than 0.8\n",
    "# (this may take a while)\n",
    "lf = ElmoLinkingRule(0.8)\n",
    "lf.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Linking Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to tagging rules, we can evaluate the accuracy of our linking rules using the ``score_linking_functions`` method.\n",
    "\n",
    "* Entity Links represents the number of correct links generated for positive classes.\n",
    "* Non-Entity Links represents the number of correct links generated for negative classes (e.g., **O** tags).\n",
    "* Incorrect links represent the total number of incorrectly generated links.\n",
    "* Accuracy represents the fraction of issued links that identified correct links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.eval import score_linking_rules\n",
    "score_linking_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, a good rule of thumb is to have all linking rules with an accuracy of above 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Progress\n",
    "We can use pickle to store the data with the tagging and linking rules applied to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('output/tmp/train_data.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open('output/tmp/dev_data.p', 'wb') as f:\n",
    "    pickle.dump(dev_data, f)\n",
    "\n",
    "with open('output/tmp/test_data.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed part 1! Now you can move on to part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
