{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to WISER, Part 2: Generative Models\n",
    "\n",
    "In this part of the tutorial, we will take the results of the labeling functions from part 1 and learn a generative model that combines them.\n",
    "\n",
    "We will start by reloading the data with the labeling function outputs from part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('output/tmp/train_data.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('output/tmp/dev_data.p', 'rb') as f:\n",
    "    dev_data = pickle.load(f)\n",
    "    \n",
    "with open('output/tmp/test_data.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the data again with all of the tagging rule annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.viewer import Viewer\n",
    "Viewer(dev_data, height=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect at the precision, recall, and F1 scores using an unweighted combination of tagging rules with ``score_labels_majority_vote``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.eval import score_labels_majority_vote\n",
    "score_labels_majority_vote(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aggregate the tagging and linking rules, we will need to train a generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to declare a generative model. In this tutorial, we will be using the *linked HMM*, a model that makes use of linking rules to model dependencies between adjacent tokens. You can use other existing generative models available at `labelmodels`. \n",
    "\n",
    "Generative moedls have the following hyperparameters:\n",
    "* Initial Accuracy (init_acc) is the initial estimated tagging and link-ing rule accuracy, also used as the mean of the prior distribution of the model parameters.\n",
    "\n",
    "* Strength of Regularization (acc_prior) is the weight of the regularizer  pulling  tagging  and  linking  rule  accuracies  toward their initial values.\n",
    "\n",
    "* Balance Prior (balance_prior) is used to regularize the class prior in Naive Bayes or the initial class distribution for HMM and Linked HMM, as well as the transition matrix in those methods, towards a more uniform distribution.\n",
    "\n",
    "We generally recommend running a grid search on the generative model hyperparameters to obtain the best performance. For more details on generative models and the *linked HMM*, please refer to our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelmodels import NaiveBayes, HMM, LinkedHMM\n",
    "from wiser.generative import Model\n",
    "\n",
    "model = Model(LinkedHMM, init_acc=0.95, acc_prior=50, balance_prior=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're done creating our generative model, we're ready to begin training! We first need to create a ``LearningConfig`` to specify the training configuration for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelmodels import LearningConfig\n",
    "\n",
    "config = LearningConfig()\n",
    "config.num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we must pass the config object to the ``train`` , alongside the training and development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs the best development score\n",
    "model.train(config, train_data=train_data, dev_data=dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily evaluate the performance of any generative model using the function ``evaluate`` function. Here, we'll evaluate our *linked HMM* on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've been following this tutorial, the test precision should be around 75.5%, and the test F1 should be around 64%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Output of the Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing your generative model, you need to save its probabilistic training labels. The ``save_probabilistic_output`` wrapper function will save the training, development, and testing outputs with the probabilistic labels to the specified directory. We will use these labels in the next part of the tutorial to train a recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_output(data=new_train, path='output/generative/link_hmm/train_data.p', save_distribution=True)\n",
    "model.save_output(data=dev_data, path='output/generative/link_hmm/dev_data.p', save_distribution=True, save_tags=True)\n",
    "model.save_output(data=test_data, path='output/generative/link_hmm/test_data.p', save_distribution=True, save_tags=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
