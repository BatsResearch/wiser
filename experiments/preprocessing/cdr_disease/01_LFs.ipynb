{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from typing import Dict\n",
    "from wiser.data.dataset_readers import CDRDiseaseDatasetReader, BioASQDatasetReader\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from wiser.lf import LabelingFunction, LinkingFunction, UMLSMatcher, DictionaryMatcher\n",
    "from allennlp.common.params import Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15acb9fe51db40479624e2264b8bdb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [01:13,  7.91it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339b0b3e5fcc4299b99430fd3ed532a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [01:14,  7.40it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4abf0b628544b0f9c5e55e8f32f9c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [01:18,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "root_directory = '../../..'\n",
    "cdr_reader = CDRDiseaseDatasetReader()\n",
    "train_data = cdr_reader.read(root_directory + '/data/cdr/CDR_TrainingSet.BioC.xml')\n",
    "dev_data = cdr_reader.read(root_directory + '/data/cdr/CDR_DevelopmentSet.BioC.xml')\n",
    "test_data = cdr_reader.read(root_directory +'/data/cdr/CDR_TestSet.BioC.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_docs = train_data + dev_data + test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applies Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_umls(docs, semantic_type, positive=True):\n",
    "    types = set([semantic_type])\n",
    "    additional_stop_words = set([\n",
    "        \"analgesic\", \"anesthesia\", \"anesthetic\", \"anterior\", \"antibiotic\",\n",
    "        \"battery\", \"brain\",\n",
    "        \"capillary\", \"cortex\", \"face\", \"grip\", \"group\", \"illness\", \"injury\", \"medulla\",\n",
    "        \"nervous\", \"nose\", \"posterior\", \"liver\", \"secondary\", \"suffer\", \"symptom\",\n",
    "        \"toxic\", \"toxic effect\"\n",
    "    ])\n",
    "    i_label = 'I' if positive else 'O'\n",
    "    lf = UMLSMatcher(\n",
    "        semantic_type, '/data/bats/2018AB', types,\n",
    "#         semantic_type, '../../../../../../../Desktop/2018AB', types,\n",
    "        additional_stop_words=additional_stop_words, i_label=i_label)\n",
    "    lf.apply(docs)\n",
    "    \n",
    "    for doc in docs:\n",
    "        for i, token in enumerate(doc['tokens']):\n",
    "            if len(token.text) <= 3:\n",
    "                doc['WISER_LABELS'][semantic_type][i] = 'ABS'\n",
    "\n",
    "        acronyms = set()\n",
    "        active = False\n",
    "        for i, label in enumerate(doc['WISER_LABELS'][semantic_type]):\n",
    "            if label[0] == i_label:\n",
    "                active = True\n",
    "            elif active and doc['tokens'][i].text == '(' and doc['tokens'][i+2].pos_ == \"PUNCT\":\n",
    "                acronyms.add(doc['tokens'][i+1].text)\n",
    "                active = False\n",
    "            else:\n",
    "                active = False\n",
    "\n",
    "        for i, token in enumerate(doc['tokens']):\n",
    "            if token.text in acronyms:\n",
    "                doc['WISER_LABELS'][semantic_type][i] = i_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Congenital Abnormality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Acquired Abnormality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Injury or Poisoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Disease or Syndrome')\n",
    "\n",
    "for doc in cdr_docs:\n",
    "    for i, token in enumerate(doc['tokens']):\n",
    "        if token.text.lower() == 'tubular' or token.text.lower() == 'ganglia'\\\n",
    "        or token.text.lower() == 'albino' or token.text.lower() == 'prostate':\n",
    "            doc['WISER_LABELS']['Disease or Syndrome'][i] = 'ABS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Mental or Behavioral Dysfunction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Cell or Molecular Dysfunction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Sign or Symptom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Neoplastic Process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Body Part, Organ, or Organ Component', positive=False)\n",
    "class BodyTerms(LabelingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [token.text.lower() for token in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        terms = set([\n",
    "            \"cancer\", \"cancers\",\n",
    "            \"damage\",\n",
    "            \"disease\", \"diseases\"\n",
    "            \"pain\",\n",
    "            \"injury\", \"injuries\",\n",
    "        ])\n",
    "        \n",
    "        for i in range(0, len(tokens)-1):\n",
    "            if instance['WISER_LABELS']['Body Part, Organ, or Organ Component'][i] == 'O':\n",
    "                if tokens[i+1] in terms:\n",
    "                    labels[i] = \"I\"\n",
    "                    labels[i+1] = \"I\"\n",
    "        return labels\n",
    "\n",
    "lf = BodyTerms()\n",
    "lf.apply(cdr_docs)\n",
    "\n",
    "for doc in cdr_docs:\n",
    "    del doc['WISER_LABELS']['Body Part, Organ, or Organ Component']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    [\"anemic\"], [\"bradycardia\"], [\"dyskinesia\"], [\"dyskinetic\"],\n",
    "    [\"hyperthermia\"], [\"hyperthermic\"], [\"hypertension\"], [\"hypertensive\"],\n",
    "    [\"hypothermia\"], [\"hypothermic\"], [\"hypotension\"], [\"hypotensive\"]\n",
    "]\n",
    "\n",
    "lf = DictionaryMatcher(\"Other Terms\", terms)\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerLike(LabelingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [token.text.lower() for token in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        token_counts = {}\n",
    "        for token in tokens:\n",
    "            if token not in token_counts:\n",
    "                token_counts[token] = 0\n",
    "            token_counts[token] += 1\n",
    "        \n",
    "        for i, token in enumerate(tokens):\n",
    "            if token_counts[token] > 0:\n",
    "                if token.endswith('edema') or token.endswith('toma') or token.endswith('coma'):\n",
    "                    labels[i] = 'I'\n",
    "        return labels\n",
    "\n",
    "lf = CancerLike()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonPrefixes(LabelingFunction):\n",
    "    \n",
    "    prefixes = {\"hyper\", \"hypo\"}\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            for prefix in self.prefixes:\n",
    "                if instance['tokens'][i].lemma_.startswith(prefix):\n",
    "                    labels[i] = 'I'\n",
    "        return labels\n",
    "    \n",
    "lf = CommonPrefixes()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    [\"acute\"], [\"chronic\"], [\"disease\"], [\"syndrome\"]\n",
    "]\n",
    "\n",
    "lf = DictionaryMatcher(\"Partial Terms\", terms)\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonSuffixes(LabelingFunction):\n",
    "    \n",
    "    suffixes = {\"agia\", \"cardia\", \"hypo\",\n",
    "                \"trophy\", \"toxic\"}\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            for suffix in self.suffixes:\n",
    "                if instance['tokens'][i].lemma_.endswith(suffix):\n",
    "                    labels[i] = 'I'\n",
    "        return labels\n",
    "    \n",
    "lf = CommonSuffixes()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Chemical', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Chemical Viewed Functionally', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Organic Chemical', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Inorganic Chemical', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Pharmacologic Substance', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Element, Ion, or Isotope', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Biologically Active Substance', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Clinical Drug', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Vitamin', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Hazardous or Poisonous Substance', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_umls(cdr_docs, 'Antibiotic', positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherPOS(LabelingFunction):\n",
    "    other_pos = {\"ADP\", \"ADV\", \"DET\", \"VERB\"}\n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(0, len(instance['tokens'])):\n",
    "            if instance['tokens'][i].pos_ in self.other_pos:\n",
    "                labels[i] = \"O\"\n",
    "        return labels\n",
    "\n",
    "lf = OtherPOS()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryWords(LabelingFunction):\n",
    "    \n",
    "    start_words = {\"develop\", \"induce\"}\n",
    "    boundary_words = {\"after\", \"before\"}\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens']) - 1):\n",
    "            if instance['tokens'][i].lemma_ in self.start_words:\n",
    "                labels[i] = 'O'\n",
    "                labels[i+1] = 'I'\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            if instance['tokens'][i].lemma_ in self.boundary_words:\n",
    "                labels[i] = 'O'\n",
    "                \n",
    "        return labels\n",
    "    \n",
    "lf = BoundaryWords()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonFP(LabelingFunction):\n",
    "    \n",
    "    words = {\"abnormality\", \"abuse\", \"acute\", \"bacterial\",\n",
    "             \"chronic\", \"consumption\",\n",
    "             \"discharge\", \"drug\", \"effect\", \"evaluable\",\n",
    "             \"fall\", \"group\", \"hepatic\",\n",
    "             \"infant\", \"infectious\", \"intoxication\",\n",
    "             \"mild\", \"myopic\", \"overload\",\n",
    "             \"perinatal\", \"plan\", \"postpartum\",\n",
    "             \"regression\", \"severe\", \"toxic\", \"withdrawl\"}\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            if instance['tokens'][i].lemma_ in self.words:\n",
    "                labels[i] = 'O'\n",
    "        return labels\n",
    "    \n",
    "lf = CommonFP()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWords(LabelingFunction):\n",
    "    \n",
    "    boundary_words = {\"a\", \"and\", \"as\", \"be\", \"in\", \"is\", \"of\", \"or\",\n",
    "                      \"that\", \"the\", \"with\"}\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            if instance['tokens'][i].lemma_ in self.boundary_words:\n",
    "                labels[i] = 'O'\n",
    "        return labels\n",
    "    \n",
    "lf = StopWords()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndNounPhrase(LabelingFunction):\n",
    "    \n",
    "    noun_tags = {\"NOUN\", \"PROPN\"}\n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        active = False\n",
    "        for i in range(len(instance['tokens'])):\n",
    "            if instance['tokens'][i].pos_ in self.noun_tags:\n",
    "                active=True\n",
    "            elif active and instance['tokens'][i].text != '-':\n",
    "                active=False\n",
    "                labels[i] = 'O'\n",
    "        return labels\n",
    "    \n",
    "lf = EndNounPhrase()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Punctuation(LabelingFunction):\n",
    "    \n",
    "    other_punc = {\".\", \",\", \"?\", \"!\", \";\", \":\", \"(\", \")\",\n",
    "                  \"%\", \"<\", \">\", \"=\", \"+\", \"/\", \"\\\\\"}\n",
    "    def apply_instance(self, instance):\n",
    "        labels = ['ABS'] * len(instance['tokens'])\n",
    "        \n",
    "        for i in range(len(instance['tokens'])):\n",
    "            if instance['tokens'][i].text in self.other_punc:\n",
    "                labels[i] = 'O'\n",
    "        return labels\n",
    "    \n",
    "lf = Punctuation()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applies Linking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PossessivePhrase(LinkingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        links = [0] * len(instance['tokens'])\n",
    "        for i in range(1, len(instance['tokens'])):\n",
    "            if instance['tokens'][i-1].text == \"'s\" or instance['tokens'][i].text == \"'s\":\n",
    "                links[i] = 1\n",
    "        \n",
    "        return links\n",
    "\n",
    "lf = PossessivePhrase()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyphenatedPhrase(LinkingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        links = [0] * len(instance['tokens'])\n",
    "        for i in range(1, len(instance['tokens'])):\n",
    "            if instance['tokens'][i-1].text == \"-\" or instance['tokens'][i].text == \"-\":\n",
    "                links[i] = 1\n",
    "        \n",
    "        return links\n",
    "\n",
    "lf = HyphenatedPhrase()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.lf import ElmoLinkingFunction\n",
    "\n",
    "lf = ElmoLinkingFunction(.8)\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonBigram(LinkingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        links = [0] * len(instance['tokens'])\n",
    "        tokens = [token.text.lower() for token in instance['tokens']]\n",
    "        \n",
    "        bigrams = {}\n",
    "        for i in range(1, len(tokens)):\n",
    "            bigram = tokens[i-1], tokens[i]\n",
    "            if bigram in bigrams:\n",
    "                bigrams[bigram] += 1\n",
    "            else:\n",
    "                bigrams[bigram] = 1\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            bigram = tokens[i-1], tokens[i]\n",
    "            count = bigrams[bigram]\n",
    "            if count >= 4:\n",
    "                links[i] = 1\n",
    "        \n",
    "        return links\n",
    "\n",
    "lf = CommonBigram()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompoundPhrase(LinkingFunction):\n",
    "    def apply_instance(self, instance):\n",
    "        links = [0] * len(instance['tokens'])\n",
    "        for i in range(1, len(instance['tokens'])):\n",
    "            if instance['tokens'][i-1].dep_ == \"compound\":\n",
    "                links[i] = 1\n",
    "        \n",
    "        return links\n",
    "\n",
    "lf = CompoundPhrase()\n",
    "lf.apply(cdr_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves Weak Supervision to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tmp/train_data.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open('tmp/dev_data.p', 'wb') as f:\n",
    "    pickle.dump(dev_data, f)\n",
    "    \n",
    "with open('tmp/test_data.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### End of Part 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
